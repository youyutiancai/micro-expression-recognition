{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.applications import InceptionResNetV2, VGG19\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dropout, concatenate, Dense, Average, Dot\n",
    "from tensorflow.keras.layers import MaxPool2D, Conv2D, Add, ReLU, Lambda\n",
    "from tensorflow.keras.layers import Input, Flatten, BatchNormalization\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from config import *\n",
    "from time import time\n",
    "import configparser\n",
    "from datetime import date\n",
    "import statistics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for apex - onset\n",
    "# emotion_data = pd.read_csv('./database/segmented_parts.csv')\n",
    "# images_lefteye, labels_lefteye = generateDataset(emotion_data, '_left_eye')\n",
    "# images_righteye, labels_righteye = generateDataset(emotion_data, '_right_eye')\n",
    "# images_mouth, labels_mouth = generateDataset(emotion_data, '_mouth')\n",
    "# images_face, labels_face = generateDataset(emotion_data, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for 1 * 1 vImages\n",
    "lefteye_vImages = np.load('./vImages/leftEye1.npz')\n",
    "left_images = np.array(lefteye_vImages['images'])\n",
    "left_labels = np.array(lefteye_vImages['labels'])\n",
    "righteye_vImages = np.load('./vImages/rightEye1.npz')\n",
    "right_images = np.array(righteye_vImages['images'])\n",
    "right_labels = np.array(righteye_vImages['labels'])\n",
    "mouth_vImages = np.load('./vImages/mouth1.npz')\n",
    "mn_images = np.array(mouth_vImages['images'])\n",
    "mn_labels = np.array(mouth_vImages['labels'])\n",
    "face_vImages = np.load('./vImages/face1.npz')\n",
    "whole_images = np.array(face_vImages['images'])\n",
    "whole_labels = np.array(face_vImages['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 3 * 3 videos\n",
    "lefteye_videos = np.load('./videos_sq3/leftEye.npz')\n",
    "left_videos = np.array(lefteye_videos['videos'])\n",
    "left_labels = np.array(lefteye_videos['labels'])\n",
    "righteye_videos = np.load('./videos_sq3/rightEye.npz')\n",
    "right_videos = np.array(righteye_videos['videos'])\n",
    "right_labels = np.array(righteye_videos['labels'])\n",
    "mouth_videos = np.load('./videos_sq3/mouth.npz')\n",
    "mn_videos = np.array(mouth_videos['videos'])\n",
    "mn_labels = np.array(mouth_videos['labels'])\n",
    "face_videos = np.load('./videos_sq3/face.npz')\n",
    "whole_videos = np.array(face_videos['videos'])\n",
    "whole_labels = np.array(face_videos['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 1 * 1 videos\n",
    "lefteye_videos = np.load('./videos_sq1/leftEye.npz')\n",
    "left_videos = np.array(lefteye_videos['videos'])\n",
    "left_labels = np.array(lefteye_videos['labels'])\n",
    "righteye_videos = np.load('./videos_sq1/rightEye.npz')\n",
    "right_videos = np.array(righteye_videos['videos'])\n",
    "right_labels = np.array(righteye_videos['labels'])\n",
    "mouth_videos = np.load('./videos_sq1/mouth.npz')\n",
    "mn_videos = np.array(mouth_videos['videos'])\n",
    "mn_labels = np.array(mouth_videos['labels'])\n",
    "face_videos = np.load('./videos_sq1/face.npz')\n",
    "whole_videos = np.array(face_videos['videos'])\n",
    "whole_labels = np.array(face_videos['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images\n",
    "def runFile(configFileName):\n",
    "\n",
    "    configFile = configparser.ConfigParser()\n",
    "    configFile.read(configFileName)\n",
    "    epoch_num = 50\n",
    "    \n",
    "    # parameters\n",
    "    square_size = int(configFile['param']['square size'])\n",
    "    output_dense = int(configFile['param']['output of dense layer'])\n",
    "    output_firstLayer = int(configFile['param']['output of first layer'])\n",
    "    output_secondLayer = int(configFile['param']['output of second layer'])\n",
    "    seed = int(configFile['param']['seed'])\n",
    "#     print(type(output_dense))\n",
    "    \n",
    "    # four landmarks\n",
    "    databaseNames = ['lefteye', 'righteye', 'mouth&nose', 'face']\n",
    "    datasets = [[left_images, left_labels], \n",
    "            [right_images, right_labels], \n",
    "            [mn_images, mn_labels], \n",
    "            [whole_images, whole_labels]]\n",
    "    \n",
    "#     #     [5, 10, 20, 40]\n",
    "#     output_dense = 10\n",
    "#     #     [8, 16, 32]\n",
    "#     output_firstLayer = 8\n",
    "#     #     [16, 32, 64]\n",
    "#     output_secondLayer = 16\n",
    "    \n",
    "    for j in range(4):\n",
    "        databaseName = databaseNames[j]\n",
    "        databaseType = 'vImage'\n",
    "        dataset = datasets[j]\n",
    "        images = dataset[0]\n",
    "        labels = dataset[1]\n",
    "    #     print(images.shape)\n",
    "        model = build_SimpleNet(input_shape=(images.shape[1], images.shape[2], 1), output_shape=5, \n",
    "                                outputsize_firstLayer = output_firstLayer, outputsize_secondLayer = output_secondLayer, \n",
    "                                outputsize_dense = output_dense)\n",
    "    #     new_output = Dense(5, activation='softmax')(model.output)\n",
    "    #     model = Model(inputs = [model.input], outputs = new_output)\n",
    "        np.random.seed(seed)\n",
    "    #     print(1)\n",
    "        perm = np.random.permutation(images.shape[0])\n",
    "        images = images[perm]\n",
    "        labels = labels[perm]\n",
    "\n",
    "        images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size = 0.2, random_state = seed)\n",
    "\n",
    "        images_train.resize(np.append(images_train.shape, [1]))\n",
    "        checkpt = ModelCheckpoint(filepath=\"simplest_network.h5\",\n",
    "                                      verbose=2,\n",
    "                                      save_best_only=True,\n",
    "                                      monitor='val_accuracy')\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='Adam',  #(learning_rate=0.00005)',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        start_time = time()\n",
    "        model_log = model.fit(images_train, labels_train,\n",
    "                              validation_split = 0.2,\n",
    "                              epochs = epoch_num,\n",
    "                              shuffle = True,\n",
    "                              callbacks = [checkpt])\n",
    "\n",
    "        end_time = time()\n",
    "\n",
    "        images_test.resize(np.append(images_test.shape, [1]))\n",
    "\n",
    "        model_best = load_model('simplest_network.h5')\n",
    "        loss_train,acc_train = model_best.evaluate(images_train,labels_train,verbose=0)\n",
    "        loss_test,acc_test = model_best.evaluate(images_test,labels_test,verbose=0)\n",
    "        print('landmark: ', j, 'epoch: ', epoch_num)\n",
    "        print()\n",
    "        print('train loss',loss_train.round(3))\n",
    "        print(' test loss',loss_test.round(3))\n",
    "        print()\n",
    "        print('train accuracy',acc_train.round(2))\n",
    "        print(' test accuracy',acc_test.round(2))\n",
    "        print()\n",
    "        print('time', (end_time - start_time) / 60)\n",
    "        \n",
    "        config = configparser.ConfigParser()\n",
    "        config['param'] = configFile['param']\n",
    "        config['info'] = {'databaseName' : databaseName,\n",
    "                         'dataType' : databaseType,\n",
    "                         'params' : model_log.params,\n",
    "                         'time' : (end_time - start_time) / 60}\n",
    "        config['result'] = {'validation_accuracy' : np.array(model_log.history['val_accuracy']).max(),\n",
    "                           'train loss' : loss_train.round(3),\n",
    "                           'test loss' : loss_test.round(3),\n",
    "                           'train accuracy' : acc_train.round(3),\n",
    "                           'test accuracy' : acc_test.round(3)}\n",
    "        config['date'] = {'date and time' : date.today()}\n",
    "        with open(configFileName, 'w') as configfile:\n",
    "            config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for square_size in [1, 2, 3]:\n",
    "for generate_image_num in range(4):\n",
    "    for times in range(20):\n",
    "        config = configparser.ConfigParser()\n",
    "        config['param'] = {'generate_image_num' : generate_image_num + 1,\n",
    "                           'output_of_first_layer' : 16,\n",
    "                           'output_of_second_layer' : 32,\n",
    "                           'output_of_dense_layer' : 5,\n",
    "                          'times' : times + 1}\n",
    "        with open('./results_sign/' + str(generate_image_num + 1) + '_16_32_5_' + str(times + 1) + '.ini', 'w') as configfile:\n",
    "            config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for videos\n",
    "def runFile_videos(configFileName):\n",
    "    \n",
    "    with open(configFileName) as fp:\n",
    "        configFile = configparser.ConfigParser()\n",
    "        configFile.read_file(fp)\n",
    "        fp.close()\n",
    "        \n",
    "    epoch_num = 50\n",
    "    \n",
    "    # parameters\n",
    "    frame_num = int(configFile['param']['generate_image_num'])\n",
    "    output_dense = int(configFile['param']['output_of_dense_layer'])\n",
    "    output_firstLayer = int(configFile['param']['output_of_first_layer'])\n",
    "    output_secondLayer = int(configFile['param']['output_of_second_layer'])\n",
    "    times = int(configFile['param']['times'])\n",
    "    databaseNames = ['lefteye', 'righteye', 'mouth&nose', 'face', 'whole_face', 'sign_face']\n",
    "    \n",
    "    face_videos = np.load('./videos/videos_sq' + str(frame_num) + '/face.npz')\n",
    "    videos = np.array(face_videos['videos'])\n",
    "    labels = np.array(face_videos['labels'])\n",
    "    \n",
    "    j = 4\n",
    "    databaseName = databaseNames[j]\n",
    "    databaseType = 'video'\n",
    "    \n",
    "    model = build_SimpleNet3D(input_shape=(videos.shape[1], videos.shape[2], videos.shape[3], 1), output_shape=5, \n",
    "                            outputsize_firstLayer = output_firstLayer, outputsize_secondLayer = output_secondLayer, \n",
    "                            outputsize_dense = output_dense)\n",
    "\n",
    "    perm = np.random.permutation(videos.shape[0])\n",
    "    videos = videos[perm]\n",
    "    labels = labels[perm]\n",
    "\n",
    "    videos_train, videos_test, labels_train, labels_test = train_test_split(videos, labels, test_size = 0.2)\n",
    "    \n",
    "    filepath = './hs/' + str(frame_num) + '_' + str(output_firstLayer) + '_' + str(output_secondLayer) + '_' + str(output_dense) + '_' + str(times) + '.h5'\n",
    "\n",
    "    videos_train.resize(np.append(videos_train.shape, [1]))\n",
    "    checkpt = ModelCheckpoint(filepath=filepath,\n",
    "                                  verbose=2,\n",
    "                                  save_best_only=True,\n",
    "                                  monitor='val_accuracy')\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "          optimizer='Adam',  #(learning_rate=0.00005)',\n",
    "           metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    start_time = time()\n",
    "    model_log = model.fit(videos_train, labels_train,\n",
    "                          validation_split = 0.2,\n",
    "                          epochs = epoch_num,\n",
    "                          shuffle = True,\n",
    "                          callbacks = [checkpt])\n",
    "\n",
    "    end_time = time()\n",
    "\n",
    "    videos_test.resize(np.append(videos_test.shape, [1]))\n",
    "\n",
    "    model_best = load_model(filepath)\n",
    "    loss_train,acc_train = model_best.evaluate(videos_train,labels_train,verbose=0)\n",
    "    loss_test,acc_test = model_best.evaluate(videos_test,labels_test,verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(videos_test, batch_size=64, verbose=1)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#     result = f1_score(labels_test, y_pred_bool, average = 'weighted')\n",
    "#     print(result)\n",
    "#     print('landmark: ', j, 'epoch: ', epoch_num)\n",
    "#     print()\n",
    "#     print('train loss',loss_train.round(3))\n",
    "#     print(' test loss',loss_test.round(3))\n",
    "#     print()\n",
    "#     print('train accuracy',acc_train.round(2))\n",
    "#     print(' test accuracy',acc_test.round(2))\n",
    "#     print('time', (end_time - start_time) / 60)\n",
    "    config = configparser.ConfigParser()\n",
    "    config['param'] = configFile['param']\n",
    "    config['info'] = {'databaseName' : databaseName,\n",
    "                     'dataType' : databaseType,\n",
    "                     'params' : model_log.params,\n",
    "                     'time' : (end_time - start_time) / 60}\n",
    "    config['result'] = {'validation_accuracy' : np.array(model_log.history['val_accuracy']).max(),\n",
    "                       'train loss' : loss_train.round(3),\n",
    "                       'test loss' : loss_test.round(3),\n",
    "                       'train accuracy' : acc_train.round(3),\n",
    "                       'test accuracy' : acc_test.round(3),\n",
    "                       'f-measure' : f1_score(labels_test, y_pred_bool, average = None),\n",
    "                       'f-measure-average' : f1_score(labels_test, y_pred_bool, average = 'weighted')}\n",
    "    config['date'] = {'date and time' : date.today()}\n",
    "    with open(configFileName, 'w') as configfile:\n",
    "        config.write(configfile)\n",
    "        configfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_16_32_5_77.ini\n",
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.6596 - accuracy: 0.3375\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51220, saving model to ./hs/2_16_32_5_77.h5\n",
      "161/161 [==============================] - 2s 15ms/sample - loss: 1.6587 - accuracy: 0.3354 - val_loss: 1.7616 - val_accuracy: 0.5122\n",
      "Epoch 2/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.1761 - accuracy: 0.5125\n",
      "Epoch 00002: val_accuracy improved from 0.51220 to 0.58537, saving model to ./hs/2_16_32_5_77.h5\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 1.1712 - accuracy: 0.5155 - val_loss: 1.3941 - val_accuracy: 0.5854\n",
      "Epoch 3/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.5750\n",
      "Epoch 00003: val_accuracy did not improve from 0.58537\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 1.0061 - accuracy: 0.5714 - val_loss: 1.2715 - val_accuracy: 0.5854\n",
      "Epoch 4/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.9389 - accuracy: 0.6375\n",
      "Epoch 00004: val_accuracy improved from 0.58537 to 0.60976, saving model to ./hs/2_16_32_5_77.h5\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.9426 - accuracy: 0.6335 - val_loss: 1.1945 - val_accuracy: 0.6098\n",
      "Epoch 5/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.7616 - accuracy: 0.7000\n",
      "Epoch 00005: val_accuracy did not improve from 0.60976\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.7569 - accuracy: 0.7019 - val_loss: 1.1672 - val_accuracy: 0.5366\n",
      "Epoch 6/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.7053 - accuracy: 0.7125\n",
      "Epoch 00006: val_accuracy did not improve from 0.60976\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.7030 - accuracy: 0.7143 - val_loss: 1.1664 - val_accuracy: 0.6098\n",
      "Epoch 7/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.6639 - accuracy: 0.7063\n",
      "Epoch 00007: val_accuracy improved from 0.60976 to 0.63415, saving model to ./hs/2_16_32_5_77.h5\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.6683 - accuracy: 0.7019 - val_loss: 1.1479 - val_accuracy: 0.6341\n",
      "Epoch 8/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.6312 - accuracy: 0.7125\n",
      "Epoch 00008: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.6273 - accuracy: 0.7143 - val_loss: 1.1622 - val_accuracy: 0.6098\n",
      "Epoch 9/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.6255 - accuracy: 0.7500\n",
      "Epoch 00009: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.6217 - accuracy: 0.7516 - val_loss: 1.2079 - val_accuracy: 0.6341\n",
      "Epoch 10/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7563\n",
      "Epoch 00010: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.5230 - accuracy: 0.7578 - val_loss: 1.2568 - val_accuracy: 0.6341\n",
      "Epoch 11/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.7750\n",
      "Epoch 00011: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.5275 - accuracy: 0.7702 - val_loss: 1.2438 - val_accuracy: 0.6098\n",
      "Epoch 12/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.7875\n",
      "Epoch 00012: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.4752 - accuracy: 0.7888 - val_loss: 1.2866 - val_accuracy: 0.6098\n",
      "Epoch 13/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.8000\n",
      "Epoch 00013: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.4596 - accuracy: 0.8012 - val_loss: 1.3905 - val_accuracy: 0.5610\n",
      "Epoch 14/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.4046 - accuracy: 0.8313\n",
      "Epoch 00014: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.4021 - accuracy: 0.8323 - val_loss: 1.4539 - val_accuracy: 0.5122\n",
      "Epoch 15/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.4300 - accuracy: 0.8000\n",
      "Epoch 00015: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.4275 - accuracy: 0.8012 - val_loss: 1.3979 - val_accuracy: 0.5122\n",
      "Epoch 16/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.3150 - accuracy: 0.9000\n",
      "Epoch 00016: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.3131 - accuracy: 0.9006 - val_loss: 1.2837 - val_accuracy: 0.5610\n",
      "Epoch 17/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.9125\n",
      "Epoch 00017: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.2926 - accuracy: 0.9130 - val_loss: 1.2795 - val_accuracy: 0.6098\n",
      "Epoch 18/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.8938\n",
      "Epoch 00018: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.2827 - accuracy: 0.8944 - val_loss: 1.3790 - val_accuracy: 0.5854\n",
      "Epoch 19/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.9375\n",
      "Epoch 00019: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.2252 - accuracy: 0.9379 - val_loss: 1.6255 - val_accuracy: 0.6098\n",
      "Epoch 20/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9187\n",
      "Epoch 00020: val_accuracy did not improve from 0.63415\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.2256 - accuracy: 0.9193 - val_loss: 1.7103 - val_accuracy: 0.6098\n",
      "Epoch 21/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9062\n",
      "Epoch 00021: val_accuracy improved from 0.63415 to 0.70732, saving model to ./hs/2_16_32_5_77.h5\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.2517 - accuracy: 0.9068 - val_loss: 1.5310 - val_accuracy: 0.7073\n",
      "Epoch 22/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9312\n",
      "Epoch 00022: val_accuracy did not improve from 0.70732\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.2065 - accuracy: 0.9317 - val_loss: 1.5214 - val_accuracy: 0.6829\n",
      "Epoch 23/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.2006 - accuracy: 0.9187\n",
      "Epoch 00023: val_accuracy did not improve from 0.70732\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.2002 - accuracy: 0.9193 - val_loss: 1.7090 - val_accuracy: 0.7073\n",
      "Epoch 24/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9375\n",
      "Epoch 00024: val_accuracy did not improve from 0.70732\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1744 - accuracy: 0.9379 - val_loss: 1.7558 - val_accuracy: 0.6829\n",
      "Epoch 25/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9312\n",
      "Epoch 00025: val_accuracy did not improve from 0.70732\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.1900 - accuracy: 0.9317 - val_loss: 1.7612 - val_accuracy: 0.6585\n",
      "Epoch 26/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1892 - accuracy: 0.9438\n",
      "Epoch 00026: val_accuracy did not improve from 0.70732\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1880 - accuracy: 0.9441 - val_loss: 1.8200 - val_accuracy: 0.6829\n",
      "Epoch 27/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9250\n",
      "Epoch 00027: val_accuracy improved from 0.70732 to 0.73171, saving model to ./hs/2_16_32_5_77.h5\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.1951 - accuracy: 0.9255 - val_loss: 1.8995 - val_accuracy: 0.7317\n",
      "Epoch 28/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9500\n",
      "Epoch 00028: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1654 - accuracy: 0.9503 - val_loss: 1.8765 - val_accuracy: 0.7317\n",
      "Epoch 29/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1378 - accuracy: 0.9688\n",
      "Epoch 00029: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1369 - accuracy: 0.9689 - val_loss: 1.9679 - val_accuracy: 0.7317\n",
      "Epoch 30/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 0.9625\n",
      "Epoch 00030: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1223 - accuracy: 0.9627 - val_loss: 2.0358 - val_accuracy: 0.7317\n",
      "Epoch 31/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9500\n",
      "Epoch 00031: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1207 - accuracy: 0.9503 - val_loss: 2.3006 - val_accuracy: 0.7073\n",
      "Epoch 32/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9688\n",
      "Epoch 00032: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1121 - accuracy: 0.9627 - val_loss: 2.3914 - val_accuracy: 0.7073\n",
      "Epoch 33/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9812\n",
      "Epoch 00033: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0970 - accuracy: 0.9814 - val_loss: 2.0028 - val_accuracy: 0.7317\n",
      "Epoch 34/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9750\n",
      "Epoch 00034: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1032 - accuracy: 0.9752 - val_loss: 1.9003 - val_accuracy: 0.7317\n",
      "Epoch 35/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9563\n",
      "Epoch 00035: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1325 - accuracy: 0.9565 - val_loss: 1.8207 - val_accuracy: 0.7317\n",
      "Epoch 36/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9750\n",
      "Epoch 00036: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0790 - accuracy: 0.9752 - val_loss: 1.8293 - val_accuracy: 0.7317\n",
      "Epoch 37/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9688\n",
      "Epoch 00037: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.1077 - accuracy: 0.9689 - val_loss: 1.7879 - val_accuracy: 0.7317\n",
      "Epoch 38/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 0.9688\n",
      "Epoch 00038: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0905 - accuracy: 0.9689 - val_loss: 1.8679 - val_accuracy: 0.7317\n",
      "Epoch 39/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9812\n",
      "Epoch 00039: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0748 - accuracy: 0.9814 - val_loss: 2.0010 - val_accuracy: 0.7317\n",
      "Epoch 40/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 0.9812\n",
      "Epoch 00040: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0703 - accuracy: 0.9814 - val_loss: 2.0641 - val_accuracy: 0.7317\n",
      "Epoch 41/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9812\n",
      "Epoch 00041: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0773 - accuracy: 0.9814 - val_loss: 2.1287 - val_accuracy: 0.7317\n",
      "Epoch 42/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9875\n",
      "Epoch 00042: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0584 - accuracy: 0.9876 - val_loss: 2.2421 - val_accuracy: 0.7317\n",
      "Epoch 43/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9875\n",
      "Epoch 00043: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0615 - accuracy: 0.9876 - val_loss: 2.3423 - val_accuracy: 0.7317\n",
      "Epoch 44/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9875\n",
      "Epoch 00044: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0554 - accuracy: 0.9876 - val_loss: 2.2859 - val_accuracy: 0.7317\n",
      "Epoch 45/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0551 - accuracy: 0.9812\n",
      "Epoch 00045: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.0556 - accuracy: 0.9814 - val_loss: 2.2844 - val_accuracy: 0.7317\n",
      "Epoch 46/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9812\n",
      "Epoch 00046: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0546 - accuracy: 0.9814 - val_loss: 2.2991 - val_accuracy: 0.7317\n",
      "Epoch 47/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9875\n",
      "Epoch 00047: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0396 - accuracy: 0.9876 - val_loss: 2.2032 - val_accuracy: 0.7317\n",
      "Epoch 48/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9812\n",
      "Epoch 00048: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.0799 - accuracy: 0.9752 - val_loss: 1.9784 - val_accuracy: 0.7073\n",
      "Epoch 49/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9812\n",
      "Epoch 00049: val_accuracy did not improve from 0.73171\n",
      "161/161 [==============================] - 1s 5ms/sample - loss: 0.0746 - accuracy: 0.9814 - val_loss: 1.4248 - val_accuracy: 0.6829\n",
      "Epoch 50/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9812\n",
      "Epoch 00050: val_accuracy improved from 0.73171 to 0.75610, saving model to ./hs/2_16_32_5_77.h5\n",
      "161/161 [==============================] - 1s 6ms/sample - loss: 0.1189 - accuracy: 0.9814 - val_loss: 1.4218 - val_accuracy: 0.7561\n",
      "51/51 [==============================] - 0s 5ms/sample\n"
     ]
    }
   ],
   "source": [
    "hss = os.listdir('./hs')\n",
    "results = os.listdir('./results')\n",
    "toRan = [hss[i].split('.')[0] for i in range(len(hss))]\n",
    "for file in results:\n",
    "    if file.split('.')[0] not in toRan:\n",
    "        print(file)\n",
    "        runFile_videos('./results/' + file)\n",
    "# os.system('mail -s \\'sent from command \\' zhouy9@rose-hulman.edu < email.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_SimpleNet(input_shape=(images_lefteye.shape[1], images_lefteye.shape[2], 1), output_shape=5)\n",
    "model2 = build_SimpleNet(input_shape=(images_righteye.shape[1], images_righteye.shape[2], 1), output_shape=5)\n",
    "model3 = build_SimpleNet(input_shape=(images_mouth.shape[1], images_mouth.shape[2], 1), output_shape=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = concatenate([model1.output, model2.output, model3.output])\n",
    "# new_out = Dense(5, activation=\"softmax\")(combined)\n",
    "model = Model(inputs=[model1.input, model2.input, model3.input], outputs=new_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5365854"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model_log.history['val_accuracy']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "images1 = images_lefteye\n",
    "perm = np.random.permutation(images1.shape[0])\n",
    "images1 = images1[perm]\n",
    "labels1 = labels_lefteye\n",
    "labels1 = labels1[perm]\n",
    "images1_train, images1_test, labels1_train, labels1_test = train_test_split(images1, labels1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "images2 = images_righteye\n",
    "images2 = images2[perm]\n",
    "labels2 = labels_righteye\n",
    "labels2 = labels2[perm]\n",
    "images2_train, images2_test, labels2_train, labels2_test = train_test_split(images2, labels2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "images3 = images_mouth\n",
    "images3 = images3[perm]\n",
    "labels3 = labels_mouth\n",
    "labels3 = labels3[perm]\n",
    "images3_train, images3_test, labels3_train, labels3_test = train_test_split(images3, labels3, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1_train.resize(np.append(images1_train.shape, [1]))\n",
    "images2_train.resize(np.append(images2_train.shape, [1]))\n",
    "images3_train.resize(np.append(images3_train.shape, [1]))\n",
    "images1_test.resize(np.append(images1_test.shape, [1]))\n",
    "images2_test.resize(np.append(images2_test.shape, [1]))\n",
    "images3_test.resize(np.append(images3_test.shape, [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "          optimizer='Adam',  #(learning_rate=0.00005)',\n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 11.4153 - accuracy: 0.2562\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.24390, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 8s 47ms/sample - loss: 11.3447 - accuracy: 0.2609 - val_loss: 32.3823 - val_accuracy: 0.2439\n",
      "Epoch 2/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.9104 - accuracy: 0.9000\n",
      "Epoch 00002: val_accuracy improved from 0.24390 to 0.26829, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 6s 39ms/sample - loss: 0.9047 - accuracy: 0.9006 - val_loss: 22.7250 - val_accuracy: 0.2683\n",
      "Epoch 3/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9937\n",
      "Epoch 00003: val_accuracy improved from 0.26829 to 0.29268, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 6s 39ms/sample - loss: 0.0124 - accuracy: 0.9938 - val_loss: 20.8624 - val_accuracy: 0.2927\n",
      "Epoch 4/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9937\n",
      "Epoch 00004: val_accuracy improved from 0.29268 to 0.34146, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 6s 39ms/sample - loss: 0.0391 - accuracy: 0.9938 - val_loss: 20.5427 - val_accuracy: 0.3415\n",
      "Epoch 5/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9812\n",
      "Epoch 00005: val_accuracy did not improve from 0.34146\n",
      "161/161 [==============================] - 6s 39ms/sample - loss: 0.0344 - accuracy: 0.9814 - val_loss: 19.6354 - val_accuracy: 0.3171\n",
      "Epoch 6/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9812\n",
      "Epoch 00006: val_accuracy improved from 0.34146 to 0.36585, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 7s 41ms/sample - loss: 0.1947 - accuracy: 0.9814 - val_loss: 21.2207 - val_accuracy: 0.3659\n",
      "Epoch 7/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.5136e-04 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve from 0.36585\n",
      "161/161 [==============================] - 6s 37ms/sample - loss: 2.4980e-04 - accuracy: 1.0000 - val_loss: 22.7724 - val_accuracy: 0.3659\n",
      "Epoch 8/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9875\n",
      "Epoch 00008: val_accuracy did not improve from 0.36585\n",
      "161/161 [==============================] - 6s 40ms/sample - loss: 0.0225 - accuracy: 0.9876 - val_loss: 22.6787 - val_accuracy: 0.3659\n",
      "Epoch 9/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.6278e-05 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve from 0.36585\n",
      "161/161 [==============================] - 12s 73ms/sample - loss: 1.6177e-05 - accuracy: 1.0000 - val_loss: 22.9910 - val_accuracy: 0.3659\n",
      "Epoch 10/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 5.9696e-04 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy improved from 0.36585 to 0.43902, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 9s 55ms/sample - loss: 5.9325e-04 - accuracy: 1.0000 - val_loss: 23.3163 - val_accuracy: 0.4390\n",
      "Epoch 11/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9937\n",
      "Epoch 00011: val_accuracy improved from 0.43902 to 0.46341, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 8s 48ms/sample - loss: 0.0106 - accuracy: 0.9938 - val_loss: 23.0698 - val_accuracy: 0.4634\n",
      "Epoch 12/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 4.2285e-04 - accuracy: 1.0000\n",
      "Epoch 00012: val_accuracy improved from 0.46341 to 0.48780, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 7s 46ms/sample - loss: 4.2022e-04 - accuracy: 1.0000 - val_loss: 22.6088 - val_accuracy: 0.4878\n",
      "Epoch 13/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n",
      "Epoch 00013: val_accuracy improved from 0.48780 to 0.51220, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 8s 49ms/sample - loss: 0.0178 - accuracy: 0.9938 - val_loss: 22.1978 - val_accuracy: 0.5122\n",
      "Epoch 14/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 5.0551e-04 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy did not improve from 0.51220\n",
      "161/161 [==============================] - 8s 47ms/sample - loss: 5.0237e-04 - accuracy: 1.0000 - val_loss: 21.8578 - val_accuracy: 0.5122\n",
      "Epoch 15/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 7.8328e-05 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.51220\n",
      "161/161 [==============================] - 7s 46ms/sample - loss: 7.7842e-05 - accuracy: 1.0000 - val_loss: 20.9992 - val_accuracy: 0.4878\n",
      "Epoch 16/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9937\n",
      "Epoch 00016: val_accuracy did not improve from 0.51220\n",
      "161/161 [==============================] - 9s 56ms/sample - loss: 0.0047 - accuracy: 0.9938 - val_loss: 20.1837 - val_accuracy: 0.5122\n",
      "Epoch 17/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 8.5681e-08 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy improved from 0.51220 to 0.53659, saving model to simplest_network.h5\n",
      "161/161 [==============================] - 9s 56ms/sample - loss: 8.5149e-08 - accuracy: 1.0000 - val_loss: 19.4554 - val_accuracy: 0.5366\n",
      "Epoch 18/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.9296e-04 - accuracy: 1.0000\n",
      "Epoch 00018: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 48ms/sample - loss: 2.9114e-04 - accuracy: 1.0000 - val_loss: 18.8648 - val_accuracy: 0.5366\n",
      "Epoch 19/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.9951e-07 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 49ms/sample - loss: 2.9765e-07 - accuracy: 1.0000 - val_loss: 18.6174 - val_accuracy: 0.5122\n",
      "Epoch 20/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 3.1292e-07 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 54ms/sample - loss: 3.1098e-07 - accuracy: 1.0000 - val_loss: 18.3142 - val_accuracy: 0.5122\n",
      "Epoch 21/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 6.4370e-07 - accuracy: 1.0000\n",
      "Epoch 00021: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 52ms/sample - loss: 6.3971e-07 - accuracy: 1.0000 - val_loss: 18.2000 - val_accuracy: 0.5122\n",
      "Epoch 22/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.3100e-06 - accuracy: 1.0000\n",
      "Epoch 00022: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 51ms/sample - loss: 2.2957e-06 - accuracy: 1.0000 - val_loss: 18.0587 - val_accuracy: 0.5122\n",
      "Epoch 23/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 3.1901e-05 - accuracy: 1.0000\n",
      "Epoch 00023: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 51ms/sample - loss: 3.1703e-05 - accuracy: 1.0000 - val_loss: 17.7522 - val_accuracy: 0.5122\n",
      "Epoch 24/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 4.8278e-07 - accuracy: 1.0000\n",
      "Epoch 00024: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 51ms/sample - loss: 4.7978e-07 - accuracy: 1.0000 - val_loss: 17.6309 - val_accuracy: 0.4878\n",
      "Epoch 25/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.7136e-08 - accuracy: 1.0000\n",
      "Epoch 00025: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 48ms/sample - loss: 1.7030e-08 - accuracy: 1.0000 - val_loss: 17.5600 - val_accuracy: 0.4878\n",
      "Epoch 26/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.9057e-08 - accuracy: 1.0000\n",
      "Epoch 00026: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 7s 43ms/sample - loss: 2.8877e-08 - accuracy: 1.0000 - val_loss: 17.5183 - val_accuracy: 0.4878\n",
      "Epoch 27/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 7.0780e-08 - accuracy: 1.0000\n",
      "Epoch 00027: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 7s 45ms/sample - loss: 7.0341e-08 - accuracy: 1.0000 - val_loss: 17.4957 - val_accuracy: 0.4878\n",
      "Epoch 28/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 5.5879e-08 - accuracy: 1.0000\n",
      "Epoch 00028: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 47ms/sample - loss: 5.5532e-08 - accuracy: 1.0000 - val_loss: 17.4947 - val_accuracy: 0.4878\n",
      "Epoch 29/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 5.5879e-08 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 49ms/sample - loss: 5.5532e-08 - accuracy: 1.0000 - val_loss: 17.0649 - val_accuracy: 0.4878\n",
      "Epoch 30/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.4728e-06 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 47ms/sample - loss: 1.4637e-06 - accuracy: 1.0000 - val_loss: 17.0913 - val_accuracy: 0.4878\n",
      "Epoch 31/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 4.3585e-07 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 48ms/sample - loss: 4.3314e-07 - accuracy: 1.0000 - val_loss: 16.9708 - val_accuracy: 0.4878\n",
      "Epoch 32/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.2583e-06 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 47ms/sample - loss: 1.2505e-06 - accuracy: 1.0000 - val_loss: 16.9921 - val_accuracy: 0.4878\n",
      "Epoch 33/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.6971e-07 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 47ms/sample - loss: 2.6803e-07 - accuracy: 1.0000 - val_loss: 16.9978 - val_accuracy: 0.4878\n",
      "Epoch 34/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 3.5092e-07 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 8s 49ms/sample - loss: 3.4874e-07 - accuracy: 1.0000 - val_loss: 16.9677 - val_accuracy: 0.4878\n",
      "Epoch 35/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 8.7389e-07 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 54ms/sample - loss: 8.6846e-07 - accuracy: 1.0000 - val_loss: 17.0159 - val_accuracy: 0.4878\n",
      "Epoch 36/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 3.4804e-06 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 59ms/sample - loss: 3.4588e-06 - accuracy: 1.0000 - val_loss: 17.0517 - val_accuracy: 0.5122\n",
      "Epoch 37/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.1101e-07 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 60ms/sample - loss: 1.1032e-07 - accuracy: 1.0000 - val_loss: 17.0638 - val_accuracy: 0.5122\n",
      "Epoch 38/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 4.6939e-08 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 57ms/sample - loss: 4.6647e-08 - accuracy: 1.0000 - val_loss: 17.1178 - val_accuracy: 0.5122\n",
      "Epoch 39/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 3.5390e-07 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 61ms/sample - loss: 3.5170e-07 - accuracy: 1.0000 - val_loss: 17.1377 - val_accuracy: 0.5122\n",
      "Epoch 40/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.3734e-06 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 61ms/sample - loss: 2.3587e-06 - accuracy: 1.0000 - val_loss: 17.1803 - val_accuracy: 0.5122\n",
      "Epoch 41/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.3767e-07 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 56ms/sample - loss: 2.3620e-07 - accuracy: 1.0000 - val_loss: 17.2276 - val_accuracy: 0.5122\n",
      "Epoch 42/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 2.3842e-08 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 65ms/sample - loss: 2.3694e-08 - accuracy: 1.0000 - val_loss: 17.2833 - val_accuracy: 0.5122\n",
      "Epoch 43/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.6660e-04 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 64ms/sample - loss: 1.6556e-04 - accuracy: 1.0000 - val_loss: 17.3286 - val_accuracy: 0.5122\n",
      "Epoch 44/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.0028e-06 - accuracy: 1.0000\n",
      "Epoch 00044: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 62ms/sample - loss: 9.9654e-07 - accuracy: 1.0000 - val_loss: 17.2490 - val_accuracy: 0.5122\n",
      "Epoch 45/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 7.4506e-08 - accuracy: 1.0000\n",
      "Epoch 00045: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 63ms/sample - loss: 7.4043e-08 - accuracy: 1.0000 - val_loss: 17.2155 - val_accuracy: 0.5122\n",
      "Epoch 46/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00046: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 10s 62ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 16.9067 - val_accuracy: 0.4878\n",
      "Epoch 47/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 6.8364e-06 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 59ms/sample - loss: 6.7939e-06 - accuracy: 1.0000 - val_loss: 17.1443 - val_accuracy: 0.4634\n",
      "Epoch 48/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.4049e-05 - accuracy: 1.0000\n",
      "Epoch 00048: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 59ms/sample - loss: 1.3962e-05 - accuracy: 1.0000 - val_loss: 17.4418 - val_accuracy: 0.3902\n",
      "Epoch 49/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 3.5633e-06 - accuracy: 1.0000\n",
      "Epoch 00049: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 59ms/sample - loss: 3.5411e-06 - accuracy: 1.0000 - val_loss: 17.6940 - val_accuracy: 0.4146\n",
      "Epoch 50/50\n",
      "160/161 [============================>.] - ETA: 0s - loss: 1.4245e-06 - accuracy: 1.0000\n",
      "Epoch 00050: val_accuracy did not improve from 0.53659\n",
      "161/161 [==============================] - 9s 56ms/sample - loss: 1.4156e-06 - accuracy: 1.0000 - val_loss: 17.8445 - val_accuracy: 0.4146\n"
     ]
    }
   ],
   "source": [
    "checkpt = ModelCheckpoint(filepath=\"simplest_network.h5\",\n",
    "                              verbose=2,\n",
    "                              save_best_only=True,\n",
    "                              monitor='val_accuracy')\n",
    "\n",
    "start_time = time()\n",
    "model_log = model.fit([images1_train, images2_train, images3_train], \n",
    "                       labels1_train,\n",
    "                      validation_split = 0.2,\n",
    "                      epochs = 50,\n",
    "                      shuffle = True,\n",
    "                      callbacks = [checkpt])\n",
    "\n",
    "end_time = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss 0.431\n",
      " test loss 3.194\n",
      "\n",
      "train accuracy 0.93\n",
      " test accuracy 0.53\n",
      "\n",
      "time 0.7416040817896525\n"
     ]
    }
   ],
   "source": [
    "model_best = load_model('simplest_network.h5')\n",
    "loss_train,acc_train = model_best.evaluate([images1_train, images2_train, images3_train],labels1_train,verbose=0)\n",
    "loss_test,acc_test = model_best.evaluate([images1_test, images2_test, images3_test],labels1_test,verbose=0)\n",
    "print()\n",
    "print('train loss',loss_train.round(3))\n",
    "print(' test loss',loss_test.round(3))\n",
    "print()\n",
    "print('train accuracy',acc_train.round(2))\n",
    "print(' test accuracy',acc_test.round(2))\n",
    "print()\n",
    "print('time', (end_time - start_time) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateData(num):\n",
    "    accus = []\n",
    "    f1s = []\n",
    "    for i in range(1, 101):\n",
    "        configFile = configparser.ConfigParser()\n",
    "        configFile.read('./results/' + str(num) + '_16_32_5_' + str(i) + '.ini')\n",
    "#         print('./results/' + str(num) + '_16_32_5_' + str(i) + '.ini')\n",
    "        accus += [float(configFile['result']['test accuracy'])]\n",
    "        f1s += [float(configFile['result']['f-measure-average'])]\n",
    "    return [accus], [f1s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bodies': [<matplotlib.collections.PolyCollection at 0x2341c6a0ba8>,\n",
       "  <matplotlib.collections.PolyCollection at 0x2341c6a0e10>,\n",
       "  <matplotlib.collections.PolyCollection at 0x2341c6bd0b8>,\n",
       "  <matplotlib.collections.PolyCollection at 0x2341c6bd320>],\n",
       " 'cmaxes': <matplotlib.collections.LineCollection at 0x2341c6a0a90>,\n",
       " 'cmins': <matplotlib.collections.LineCollection at 0x2341c407a20>,\n",
       " 'cbars': <matplotlib.collections.LineCollection at 0x2341c407a58>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accus1, f1s1 = generateData(1)\n",
    "accus2, f1s2 = generateData(2)\n",
    "accus3, f1s3 = generateData(3)\n",
    "accus4, f1s4 = generateData(4)\n",
    "plt.xlabel('Number of generated images')\n",
    "plt.ylabel('F1 score')\n",
    "plt.violinplot(f1s1 + f1s2 + f1s3 + f1s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bodies': [<matplotlib.collections.PolyCollection at 0x2341c72fc88>,\n",
       "  <matplotlib.collections.PolyCollection at 0x2341c72fef0>,\n",
       "  <matplotlib.collections.PolyCollection at 0x2341c73d198>,\n",
       "  <matplotlib.collections.PolyCollection at 0x2341c73d400>],\n",
       " 'cmaxes': <matplotlib.collections.LineCollection at 0x2341c72fbe0>,\n",
       " 'cmins': <matplotlib.collections.LineCollection at 0x2341c73d240>,\n",
       " 'cbars': <matplotlib.collections.LineCollection at 0x2341c73d940>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Number of generated images')\n",
    "plt.ylabel('accuracy')\n",
    "plt.violinplot(accus1 + accus2 + accus3 + accus4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71996\n",
      "0.725\n",
      "0.71033\n",
      "0.706\n",
      "0.70501\n",
      "0.706\n",
      "0.69017\n",
      "0.696\n"
     ]
    }
   ],
   "source": [
    "# print(accus1)\n",
    "print(statistics.mean(accus1[0]))\n",
    "print(statistics.median(accus1[0]))\n",
    "print(statistics.mean(accus2[0]))\n",
    "print(statistics.median(accus2[0]))\n",
    "print(statistics.mean(accus3[0]))\n",
    "print(statistics.median(accus3[0]))\n",
    "print(statistics.mean(accus4[0]))\n",
    "print(statistics.median(accus4[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7030281891813417\n",
      "0.7232923484850604\n",
      "0.6951840014693321\n",
      "0.6996173047897185\n",
      "0.6873155405922082\n",
      "0.6988555226011974\n",
      "0.6771736500369157\n",
      "0.6960252681614911\n"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(f1s1[0]))\n",
    "print(statistics.median(f1s1[0]))\n",
    "print(statistics.mean(f1s2[0]))\n",
    "print(statistics.median(f1s2[0]))\n",
    "print(statistics.mean(f1s3[0]))\n",
    "print(statistics.median(f1s3[0]))\n",
    "print(statistics.mean(f1s4[0]))\n",
    "print(statistics.median(f1s4[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algo(images, outputNum):\n",
    "    imageNum = images.shape[0]\n",
    "    framePerImg = (imageNum - 1) / (outputNum + 1)\n",
    "    previousFrame = images[0]\n",
    "    result = np.zeros([outputNum, images[0].shape[0], images[0].shape[1]])\n",
    "    for i in range(outputNum):\n",
    "        currentImg = (i + 1) * framePerImg\n",
    "        low = images[int(np.floor(currentImg))]\n",
    "        high = images[int(np.ceil(currentImg))]\n",
    "#         print(currentImg - np.floor(currentImg))\n",
    "        currentNew = low + (high - low) * (currentImg - np.floor(currentImg))\n",
    "        result[i] = currentNew - previousFrame\n",
    "        previousFrame = currentNew\n",
    "    return result.astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
